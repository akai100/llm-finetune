train_file: data/raw/train.jsonl
output_dir: outputs/checkpoints
num_train_epochs: 3
per_device_train_batch_size: 2
gradient_accumulation_steps: 8
learning_rate: 2e-4
logging_steps: 10
save_steps: 500
eval_steps: 500
max_len: 2048
fp16: true
bf16: false
resume_from: null

compression:
  enabled: true

  distillation:
    enabled: true
    temperature: 2.0
    alpha: 0.7

  pruning:
    enabled: true
    type: structured          # structured | unstructured
    target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
    sparsity: 0.3             # 30% 剪枝
    schedule: linear          # linear | step
    start_step: 1000
    end_step: 5000

  quantization:
    enabled: true
    mode: post                # post | qat
    bits: 8                   # 8bit / 4bit
    backend: bitsandbytes     # bitsandbytes | gptq

